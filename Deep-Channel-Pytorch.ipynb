{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Channel-Pytorch\n",
    "\n",
    "**Deep-Channel**的Pytorch实现，并进行了一定的修改\n",
    "\n",
    "*By: Roger Zhu*\n",
    "\n",
    "![图片被吃掉啦！](./images/title_ohne_abs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as tud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set device\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "# set random seed\n",
    "SEED = 10015\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# hyperparameters\n",
    "# data\n",
    "time_batch = 500000\n",
    "\n",
    "# 1D-CNN\n",
    "OUT_DIM = 64\n",
    "\n",
    "# LSTM\n",
    "N_STEP = 100\n",
    "N_HIDDEN = 256\n",
    "N_LAYER = 3\n",
    "\n",
    "# train\n",
    "EPOCHS = 50\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_channel = train_df.iloc[:, -1].max()\n",
    "time_batch_sz = len(train_df) // time_batch\n",
    "\n",
    "train_data = torch.tensor(\n",
    "    train_df.iloc[:, -2], dtype=torch.float32, device=DEVICE)\n",
    "train_label = torch.tensor(\n",
    "    train_df.iloc[:, -1], dtype=torch.int64, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_Dataset(tud.Dataset):\n",
    "    def __init__(self, data, label, time_batch, time_batch_sz):\n",
    "        super(train_Dataset, self).__init__()\n",
    "        self.time_batch = time_batch\n",
    "        self.time_batch_sz = time_batch_sz\n",
    "        self.data = data.view(self.time_batch_sz, self.time_batch, 1)\n",
    "        self.label = label.view(self.time_batch_sz, self.time_batch, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.time_batch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # dataloader output: (n_step, time_batch_size(B), 1)\n",
    "        # get last time_batch_sz as validation data\n",
    "        return ((self.data[:-1, idx, :], self.label[:-1, idx, :]),\n",
    "                (self.data[-1:, idx, :], self.label[-1:, idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_Dataset(train_data, train_label, time_batch, time_batch_sz)\n",
    "train_dl = tud.DataLoader(train_ds, shuffle=False, batch_size=N_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_hidden, n_layer, max_channel, out_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layer = n_layer\n",
    "        self.max_channel = max_channel\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.conv = nn.Conv1d(1, self.out_dim, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.out_dim)\n",
    "        self.lstm = nn.LSTM(self.out_dim, self.n_hidden,\n",
    "                            self.n_layer, dropout=0.2)\n",
    "        self.ln1 = nn.Linear(self.n_hidden, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.ln2 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.ln3 = nn.Linear(64, self.max_channel + 1)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # input_size: (n_step, B, 1)\n",
    "        x = x.permute(1, 2, 0).contiguous()  # (B, 1, n_step)\n",
    "        x = F.relu(self.bn1(self.conv(x)))  # (B, out_dim, n_step)\n",
    "        x = x.permute(2, 0, 1).contiguous()  # (n_step, B, out_dim)\n",
    "        x, hidden = self.lstm(x, hidden)  # (n_step, B, n_hidden)\n",
    "        x = x.view(-1, self.n_hidden)  # (n_step * B, n_hidden)\n",
    "        x = F.relu(self.bn2(self.ln1(x)))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.bn3(self.ln2(x)))\n",
    "        x = self.drop(x)\n",
    "        output = self.ln3(x)  # (n_step * B, max_channel + 1)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initweight(self):\n",
    "        initrange = 0.1\n",
    "        self.conv.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ln1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ln2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ln3.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.conv.bias.data.zero_()\n",
    "        self.ln1.bias.data.zero_()\n",
    "        self.ln2.bias.data.zero_()\n",
    "        self.ln3.bias.data.zero_()\n",
    "\n",
    "    def inithidden(self, batch_size, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.n_layer, batch_size, self.n_hidden, requires_grad=requires_grad),\n",
    "                weight.new_zeros(self.n_layer, batch_size, self.n_hidden, requires_grad=requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(N_HIDDEN, N_LAYER, max_channel, OUT_DIM)\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "model.initweight()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_list = []\n",
    "epoch_acc_list = []\n",
    "epoch_val_loss_list = []\n",
    "epoch_val_acc_list = []\n",
    "max_val_acc = None\n",
    "for epoch in range(EPOCHS):\n",
    "    hidden = model.inithidden(time_batch_sz - 1)\n",
    "    val_hidden = model.inithidden(1)\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_acc = 0\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        (data, label), (val_data, val_label) = batch\n",
    "        if USE_CUDA:\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "            val_data = val_data.cuda()\n",
    "            val_label = val_label.cuda()\n",
    "        label = label.view(-1, label.shape[-1]).squeeze(-1)\n",
    "        val_label = val_label.view(-1, val_label.shape[-1]).squeeze(-1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output, val_hidden = model(val_data, val_hidden)\n",
    "            val_loss = loss_fn(val_output, val_label)\n",
    "            val_acc = (torch.argmax(val_output, dim=1)\n",
    "                       == val_label).cpu().sum().numpy() / len(val_label)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            epoch_val_acc += val_acc\n",
    "        model.train()\n",
    "        hidden = tuple(c.detach() for c in hidden)\n",
    "        output, hidden = model(data, hidden)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        acc = (torch.argmax(output, dim=1) ==\n",
    "               label).cpu().sum().numpy() / len(label)\n",
    "        epoch_acc += acc\n",
    "        if i % 10 == 0:\n",
    "            print('loss:', loss.item(), 'acc:', acc, '\\n',\n",
    "                  'val_loss:', val_loss.item(), 'val_acc:', val_acc)\n",
    "            if max_val_acc == None or val_acc > max_val_acc:\n",
    "                torch.save(model.state_dict(), 'best.th')\n",
    "                max_val_acc = val_acc\n",
    "                print('model state saved!')\n",
    "    epoch_loss = epoch_loss / i\n",
    "    epoch_acc = epoch_acc / i\n",
    "    epoch_val_loss = epoch_val_loss / i\n",
    "    epoch_val_acc = epoch_val_acc / i\n",
    "    if epoch > 0:\n",
    "        if epoch_acc < epoch_acc_list[-1]:\n",
    "            scheduler.step()\n",
    "            print('learning rate changed!')\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_acc_list.append(epoch_acc)\n",
    "    epoch_val_loss_list.append(epoch_val_loss)\n",
    "    epoch_val_acc_list.append(epoch_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_loss_list, label='loss')\n",
    "plt.plot(epoch_val_loss_list, label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_acc_list, label='acc')\n",
    "plt.plot(epoch_val_acc_list, label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()\n",
    "test_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_bsz = len(test_df) // time_batch\n",
    "test_data = torch.tensor(\n",
    "    test_df.iloc[:, -1], dtype=torch.float32, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_Dataset(tud.Dataset):\n",
    "    def __init__(self, data, time_batch, time_batch_sz):\n",
    "        super(test_Dataset, self).__init__()\n",
    "        self.time_batch = time_batch\n",
    "        self.time_batch_sz = time_batch_sz\n",
    "        self.data = data.view(self.time_batch_sz, self.time_batch, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.time_batch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # dataloader output: (n_step, time_batch_size(B), 1)\n",
    "        return self.data[:, idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_Dataset(test_data, time_batch, test_time_bsz)\n",
    "test_dl = tud.DataLoader(test_ds, shuffle=False, batch_size=N_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best.th', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "pred = None\n",
    "with torch.no_grad():\n",
    "    hidden = model.inithidden(test_time_bsz, requires_grad=False)\n",
    "    for data in test_dl:\n",
    "        if USE_CUDA:\n",
    "            data = data.cuda()\n",
    "        output, hidden = model(data, hidden)  # (n_step * B, max_channel + 1)\n",
    "        # (n_step, B, max_channel + 1)\n",
    "        output = output.view(N_STEP, test_time_bsz, -1)\n",
    "        if pred == None:\n",
    "            pred = torch.argmax(output, dim=2).permute(1, 0)  # (B, n_step)\n",
    "        else:\n",
    "            pred = torch.cat(\n",
    "                (pred, torch.argmax(output, dim=2).permute(1, 0)), dim=1)\n",
    "    pred = pred.view(test_time_bsz * time_batch)\n",
    "    pred = pred.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.iloc[:, -1] = pred\n",
    "submission.to_csv('submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
